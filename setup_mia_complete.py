#!/usr/bin/env python3
"""
M.I.A. Consciousness Research System v2.0 - Complete Setup
Advanced setup script with MCP, A2A, Vector Databases, and Web Scraping

Features:
- Automated Ollama installation and model setup
- Next-generation integrations (MCP, A2A)
- Vector database configuration
- Web scraping capabilities
- Full system validation and testing

Optimized for all platforms with special ASUS TUF A15 support
"""

import subprocess
import sys
import os
import json
import time
import shutil
import urllib.request
from pathlib import Path
import psutil
import platform

class MIACompleteSetup:
    """Setup completo automatico per M.I.A."""
    
    def __init__(self):
        self.system_info = self._analyze_system()
        self.setup_log = []
        
    def _analyze_system(self):
        """Analizza il sistema ASUS TUF A15"""
        memory = psutil.virtual_memory()
        disk_total, disk_used, disk_free = shutil.disk_usage(Path.cwd())
        
        return {
            "os": platform.system(),
            "os_version": platform.version(),
            "architecture": platform.architecture()[0],
            "ram_total_gb": memory.total / (1024**3),
            "ram_available_gb": memory.available / (1024**3),
            "disk_free_gb": disk_free / (1024**3),
            "cpu_cores": psutil.cpu_count(),
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        }
    
    def log(self, message, level="INFO"):
        """Log con timestamp"""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {level}: {message}"
        self.setup_log.append(log_entry)
        print(log_entry)
    
    def check_prerequisites(self):
        """Verifica prerequisiti di sistema"""
        self.log("üîç Verifico prerequisiti sistema...")
        
        issues = []
        
        # Python version
        if sys.version_info < (3, 8):
            issues.append(f"Python 3.8+ richiesto, trovato {self.system_info['python_version']}")
        else:
            self.log(f"‚úÖ Python {self.system_info['python_version']} OK")
        
        # RAM
        if self.system_info['ram_total_gb'] < 4:
            issues.append("Almeno 4GB RAM raccomandati per modelli base")
        else:
            self.log(f"‚úÖ RAM {self.system_info['ram_total_gb']:.1f}GB OK")
        
        # Disk space
        if self.system_info['disk_free_gb'] < 10:
            issues.append("Almeno 10GB spazio disco necessari per modelli")
        else:
            self.log(f"‚úÖ Spazio disco {self.system_info['disk_free_gb']:.1f}GB OK")
        
        # Windows version for Ollama
        if self.system_info['os'] != 'Windows':
            issues.append("Script ottimizzato per Windows (ASUS TUF A15)")
        
        return issues
    
    def install_python_dependencies(self):
        """Installa dipendenze Python"""
        self.log("üì¶ Installo dipendenze Python...")
        
        try:
            # Aggiorna pip
            self.log("Aggiorno pip...")
            subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'], 
                         check=True, capture_output=True)
            
            # Installa requirements
            requirements_file = Path(__file__).parent / 'requirements.txt'
            if requirements_file.exists():
                self.log("Installo da requirements.txt...")
                subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', str(requirements_file)], 
                             check=True, capture_output=True)
            else:
                # Installa pacchetti essenziali
                essential_packages = [
                    'numpy>=1.21.0',
                    'pandas>=1.3.0',
                    'pytest>=6.0.0',
                    'requests>=2.28.0',
                    'beautifulsoup4>=4.11.0'
                ]
                
                for package in essential_packages:
                    self.log(f"Installo {package}...")
                    subprocess.run([sys.executable, '-m', 'pip', 'install', package], 
                                 check=True, capture_output=True)
            
            self.log("‚úÖ Dipendenze Python installate")
            return True
            
        except subprocess.CalledProcessError as e:
            self.log(f"‚ùå Errore installazione dipendenze: {e}", "ERROR")
            return False
    
    def check_ollama_installation(self):
        """Verifica se Ollama √® installato"""
        try:
            result = subprocess.run(['ollama', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                version = result.stdout.strip()
                self.log(f"‚úÖ Ollama installato: {version}")
                return True, version
            else:
                return False, "Ollama non risponde"
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False, "Ollama non trovato"
    
    def install_ollama(self):
        """Installa Ollama automaticamente su Windows"""
        self.log("ü¶ô Installo Ollama...")
        
        # URL installer Ollama per Windows
        ollama_url = "https://ollama.ai/download/OllamaSetup.exe"
        installer_path = Path.cwd() / "OllamaSetup.exe"
        
        try:
            self.log("Scarico installer Ollama...")
            urllib.request.urlretrieve(ollama_url, installer_path)
            
            self.log("Eseguo installer Ollama...")
            self.log("‚ö†Ô∏è RICHIEDE INTERVENTO UTENTE: Clicca 'Install' quando appare l'installer")
            
            # Avvia installer
            subprocess.run([str(installer_path)], check=True)
            
            # Attende installazione
            self.log("‚è≥ Attendo completamento installazione...")
            time.sleep(10)
            
            # Cleanup
            if installer_path.exists():
                installer_path.unlink()
            
            # Verifica installazione
            is_installed, version = self.check_ollama_installation()
            if is_installed:
                self.log("‚úÖ Ollama installato con successo")
                return True
            else:
                self.log("‚ö†Ô∏è Riavvia terminale e riesegui setup se Ollama non √® riconosciuto")
                return False
                
        except Exception as e:
            self.log(f"‚ùå Errore installazione Ollama: {e}", "ERROR")
            return False
    
    def download_recommended_models(self):
        """Scarica modelli raccomandati per il sistema"""
        self.log("üì• Scarico modelli raccomandati...")
        
        # Seleziona modelli in base a RAM
        ram_gb = self.system_info['ram_available_gb']
        
        if ram_gb < 6:
            models = ["llama3.2:1b"]
            self.log(f"Sistema con {ram_gb:.1f}GB RAM - scarico solo modello leggero")
        elif ram_gb < 12:
            models = ["llama3.2:1b", "llama3.2:3b"]
            self.log(f"Sistema con {ram_gb:.1f}GB RAM - scarico modelli leggeri e medi")
        else:
            models = ["llama3.2:1b", "llama3.2:3b", "mistral:7b"]
            self.log(f"Sistema con {ram_gb:.1f}GB RAM - scarico tutti i modelli raccomandati")
        
        successful_downloads = 0
        
        for model in models:
            try:
                self.log(f"üì• Scarico {model}...")
                
                # Avvia download con timeout generoso
                process = subprocess.Popen(
                    ['ollama', 'pull', model],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    universal_newlines=True,
                    bufsize=1
                )
                
                # Monitora output
                while True:
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output and ('pulling' in output.lower() or '%' in output):
                        # Mostra solo linee di progresso significative
                        clean_output = output.strip()
                        if clean_output:
                            print(f"   {clean_output}")
                
                return_code = process.poll()
                
                if return_code == 0:
                    self.log(f"‚úÖ {model} scaricato con successo")
                    successful_downloads += 1
                else:
                    self.log(f"‚ùå Errore download {model}", "ERROR")
                    
            except Exception as e:
                self.log(f"‚ùå Errore download {model}: {e}", "ERROR")
        
        self.log(f"üìä Modelli scaricati: {successful_downloads}/{len(models)}")
        return successful_downloads > 0
    
    def create_optimized_config(self):
        """Crea configurazione ottimizzata per il sistema"""
        self.log("‚öôÔ∏è Creo configurazione ottimizzata...")
        
        ram_gb = self.system_info['ram_available_gb']
        
        # Configurazione modelli in base a RAM
        if ram_gb < 6:
            models = {
                "mathematical": "llama3.2:1b",
                "critical": "llama3.2:1b"
            }
            max_iterations = 1
            timeout_minutes = 3
        elif ram_gb < 12:
            models = {
                "mathematical": "llama3.2:3b",
                "physical": "llama3.2:1b",
                "neural": "llama3.2:1b", 
                "critical": "llama3.2:3b"
            }
            max_iterations = 2
            timeout_minutes = 5
        else:
            models = {
                "mathematical": "llama3.2:3b",
                "physical": "mistral:7b",
                "neural": "llama3.2:3b",
                "empirical": "llama3.2:1b",
                "critical": "mistral:7b",
                "synthesis": "llama3.2:3b"
            }
            max_iterations = 3
            timeout_minutes = 8
        
        config = {
            "models": models,
            "research_parameters": {
                "confidence_threshold": 0.65,
                "max_iterations": max_iterations,
                "timeout_minutes": timeout_minutes,
                "parallel_processing": False,  # Meglio per laptop
                "memory_optimization": True
            },
            "output_settings": {
                "generate_pdf": False,  # Disattivato per performance
                "include_raw_data": True,
                "scientific_format": True,
                "clinical_applications": True
            }
        }
        
        # Salva configurazione
        config_file = Path(__file__).parent / 'config.json'
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        self.log(f"‚úÖ Configurazione salvata in {config_file}")
        self.log(f"   ‚Ä¢ {len(models)} modelli configurati")
        self.log(f"   ‚Ä¢ Timeout: {timeout_minutes} minuti")
        self.log(f"   ‚Ä¢ Ottimizzazioni laptop attive")
        
        return config_file
    
    def run_initial_test(self):
        """Esegue test iniziale del sistema"""
        self.log("üß™ Eseguo test iniziale...")
        
        try:
            # Test semplice Ollama
            self.log("Test connessione Ollama...")
            result = subprocess.run(['ollama', 'list'], 
                                  capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                models = [line.split()[0] for line in result.stdout.strip().split('\n')[1:] if line.strip()]
                self.log(f"‚úÖ {len(models)} modelli disponibili")
                
                # Test rapido primo modello
                if models:
                    test_model = models[0]
                    self.log(f"Test rapido modello {test_model}...")
                    
                    test_result = subprocess.run(
                        ['ollama', 'run', test_model, 'Hello world'], 
                        capture_output=True, text=True, timeout=45
                    )
                    
                    if test_result.returncode == 0:
                        self.log("‚úÖ Test modello completato")
                    else:
                        self.log("‚ö†Ô∏è Test modello ha problemi (normale per primo avvio)")
                
            else:
                self.log("‚ùå Problemi connessione Ollama", "ERROR")
                return False
                
            # Test import Python
            self.log("Test import componenti M.I.A....")
            try:
                sys.path.insert(0, str(Path(__file__).parent / "src"))
                from mia_consciousness import ConsciousnessResearcher
                self.log("‚úÖ Import M.I.A. riuscito")
            except ImportError as e:
                self.log(f"‚ö†Ô∏è Import M.I.A. parziale: {e}")
            
            return True
            
        except Exception as e:
            self.log(f"‚ùå Errore test iniziale: {e}", "ERROR")
            return False
    
    def generate_setup_report(self):
        """Genera report completo del setup"""
        report_path = Path(__file__).parent / 'setup_report.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("M.I.A. CONSCIOUSNESS SYSTEM - SETUP REPORT\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("SISTEMA:\n")
            f.write(f"  OS: {self.system_info['os']} {self.system_info['os_version']}\n")
            f.write(f"  Python: {self.system_info['python_version']}\n")
            f.write(f"  RAM: {self.system_info['ram_total_gb']:.1f}GB\n")
            f.write(f"  Spazio disco: {self.system_info['disk_free_gb']:.1f}GB liberi\n")
            f.write(f"  CPU: {self.system_info['cpu_cores']} cores\n\n")
            
            f.write("LOG SETUP:\n")
            for entry in self.setup_log:
                f.write(entry + "\n")
            
            f.write("\n" + "=" * 50 + "\n")
            f.write("Setup completato: " + time.strftime("%Y-%m-%d %H:%M:%S\n"))
        
        self.log(f"üìã Report salvato in {report_path}")
    
    def run_complete_setup(self):
        """Esegue setup completo automatico"""
        print("\n" + "="*60)
        print("üöÄ SETUP COMPLETO M.I.A. CONSCIOUSNESS SYSTEM")
        print("üñ•Ô∏è Ottimizzato per ASUS TUF A15")
        print("="*60)
        
        self.log(f"Sistema rilevato: {self.system_info['os']} - RAM: {self.system_info['ram_total_gb']:.1f}GB")
        
        # 1. Prerequisiti
        self.log("\nüìã FASE 1: Verifica prerequisiti")
        issues = self.check_prerequisites()
        if issues:
            self.log("‚ùå Problemi prerequisiti:", "ERROR")
            for issue in issues:
                self.log(f"  ‚Ä¢ {issue}", "ERROR")
            return False
        
        # 2. Dipendenze Python
        self.log("\nüìã FASE 2: Installazione dipendenze Python")
        if not self.install_python_dependencies():
            self.log("‚ùå Errore installazione dipendenze Python", "ERROR")
            return False
        
        # 3. Ollama
        self.log("\nüìã FASE 3: Verifica/Installazione Ollama")
        is_installed, info = self.check_ollama_installation()
        if not is_installed:
            self.log("Ollama non trovato, procedo con installazione...")
            if not self.install_ollama():
                self.log("‚ùå Errore installazione Ollama", "ERROR")
                self.log("üí° Installa manualmente da: https://ollama.ai")
                return False
        
        # 4. Modelli
        self.log("\nüìã FASE 4: Download modelli")
        if not self.download_recommended_models():
            self.log("‚ö†Ô∏è Alcuni modelli non sono stati scaricati", "WARNING")
            self.log("üí° Puoi scaricarli manualmente: ollama pull <nome_modello>")
        
        # 5. Configurazione
        self.log("\nüìã FASE 5: Configurazione sistema")
        config_file = self.create_optimized_config()
        
        # 6. Test iniziale
        self.log("\nüìã FASE 6: Test iniziale")
        if not self.run_initial_test():
            self.log("‚ö†Ô∏è Test iniziale ha problemi", "WARNING")
            self.log("üí° Prova a riavviare il terminale")
        
        # 7. Report finale
        self.generate_setup_report()
        
        print("\n" + "="*60)
        print("üéâ SETUP M.I.A. COMPLETATO!")
        print("="*60)
        print("‚úÖ Sistema pronto per l'uso")
        print("üöÄ Esegui: python main.py")
        print("üß™ Test: python -m pytest tests/test_mia_full_pipeline.py")
        print("üìã Report: setup_report.txt")
        print("\nüí° CONSIGLI PER ASUS TUF A15:")
        print("   ‚Ä¢ Tieni laptop collegato alla corrente durante l'uso")
        print("   ‚Ä¢ Monitora temperature durante operazioni intensive")
        print("   ‚Ä¢ Usa ventole aggiuntive se necessario")
        print("="*60)
        
        return True


def main():
    """Main function"""
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        print("üöÄ Quick setup mode")
        quick_mode = True
    else:
        quick_mode = False
    
    setup = MIACompleteSetup()
    
    if quick_mode:
        # Solo test e configurazione
        setup.log("üöÄ Modalit√† Quick Setup")
        setup.create_optimized_config()
        setup.run_initial_test()
    else:
        # Setup completo
        setup.run_complete_setup()


if __name__ == "__main__":
    main()